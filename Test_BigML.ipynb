{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Give Me Credit: Kaggle competition</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première Etape : Importation des librairies nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigml.api import BigML\n",
    "from pandas import read_csv\n",
    "import kaggle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center>Préciser l'id du projet BigML</center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = BigML(project= 'project/5d94a407eba31d45c8000088')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deuxième Etape: Importer les données de train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center>Créer le dataset de training: trainfull</center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv('../handson-ml2/kaggle-give-me-credit-train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n",
    "df['IncomePerPerson'] = df['MonthlyIncome']/ (df['NumberOfDependents']+1)\n",
    "df['NumberOfDaysLate'] = df['NumberOfTimes90DaysLate']+ df['NumberOfTime60-89DaysPastDueNotWorse']+ df['NumberOfTime30-59DaysPastDueNotWorse']\n",
    "df['NumberCreditLines'] = df['NumberOfOpenCreditLinesAndLoans']- df['NumberRealEstateLoansOrLines']\n",
    "df['MonthlyDebt'] = df['MonthlyIncome'] * df['DebtRatio']\n",
    "df['MonthlyBalance'] = df['MonthlyIncome'] - df['MonthlyDebt']\n",
    "df = df.rename(columns={\"Unnamed: 0\": \"Id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"trainfull.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = api.create_source('../handson-ml2/trainfull.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_dataset = api.create_dataset(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troisième étape: Séparation en train et val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center>Split 80/20 du trainfull en train et validation</center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = api.create_dataset (origin_dataset, {\"name\": \"Train80\", \"sample_rate\":0.8, \"seed\": \"myseed\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = api.create_dataset (origin_dataset, {\"name\": \"Val\", \"sample_rate\":0.8, \"seed\": \"myseed\", \"out_of_bag\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quatrième étape: Modèle d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center>Lancement d'un Modèle ou d'un Deepnet ou autre...</center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = api.create_ensemble(train_dataset, {\"objective_field\":\"SeriousDlqin2yrs\"})\n",
    "api.ok(ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center>Evaluation du modèle</center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = api.create_evaluation(ensemble, val_dataset)\n",
    "api.status(evaluation)\n",
    "api.ok(evaluation)\n",
    "evaluation = api.get_evaluation(evaluation)\n",
    "api.pprint(evaluation['object']['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center>Lancer la prediction à partir de notre modèle en demandant les probabilités</center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction = api.create_batch_prediction(ensemble, val_dataset, {\"all_fields\": True, \"header\": True, \"probabilities\": True})\n",
    "api.ok(batch_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center>Récupérer la batch prediction au format csv</center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.download_batch_prediction(batch_prediction, filename='../handson-ml2/my_predictionsvalidation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = read_csv('../handson-ml2/my_predictionsvalidation.csv')\n",
    "df = df.rename(columns={\"SeriousDlqin2yrs.1\":\"MyPrediction\"})\n",
    "df = df.drop(columns={\"field1\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cinquième étape: vérifier les erreurs pour évaluer notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TN = 0\n",
    "TP = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "\n",
    "serie = df.transpose() # here we convert the DataFrame into a Serie\n",
    "for ligne in serie:\n",
    "    if(serie[ligne]['SeriousDlqin2yrs'] == 0 and serie[ligne]['MyPrediction'] == 0):\n",
    "             TN = TN + 1\n",
    "            \n",
    "    if(serie[ligne]['SeriousDlqin2yrs'] == 1 and serie[ligne]['MyPrediction'] == 1):\n",
    "             TP = TP + 1\n",
    "\n",
    "    if(serie[ligne]['SeriousDlqin2yrs'] == 1 and serie[ligne]['MyPrediction'] == 0):\n",
    "             FN = FN + 1\n",
    "\n",
    "    if(serie[ligne]['SeriousDlqin2yrs'] == 0 and serie[ligne]['MyPrediction'] == 1):\n",
    "             FP = FP + 1\n",
    "            \n",
    "print(f\"TN : {TN}\")\n",
    "print(f\"TP : {TP}\")\n",
    "print(f\"FN : {FN}\")\n",
    "print(f\"FP : {FP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center> Ajouter une colonne erreur contenant les TN,FN, TP, FP</center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(row):\n",
    "    if row['SeriousDlqin2yrs'] == 0 and row['MyPrediction'] == 0:\n",
    "        error_value = 'TN'\n",
    "    if row['SeriousDlqin2yrs'] == 1 and row['MyPrediction'] == 1:\n",
    "        error_value = 'TP'\n",
    "    if row['SeriousDlqin2yrs'] == 1 and row['MyPrediction'] == 0:\n",
    "        error_value = 'FN'\n",
    "    if row['SeriousDlqin2yrs'] == 0 and row['MyPrediction'] == 1:\n",
    "        error_value = 'FP'\n",
    "    return error_value\n",
    "\n",
    "df['error'] = df.apply(confusion, axis = 1)\n",
    "df.to_csv('../handson-ml2/kaggle-give-me-credit-train_confusion.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = read_csv('../handson-ml2/kaggle-give-me-credit-train_confusion.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center> Mesurer l'accuracy, compter les différentes erreurs, et construire une matrice de confusion</center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TN+TP)/(TP+TN+FP+FN)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice = df['error'].value_counts()\n",
    "matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv('../handson-ml2/kaggle-give-me-credit-train_confusion.csv')\n",
    "\n",
    "data = pd.DataFrame(data, columns=['SeriousDlqin2yrs','MyPrediction'])\n",
    "\n",
    "confusion_matrix = pd.crosstab(df['SeriousDlqin2yrs'], df['MyPrediction'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print (confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center> Calculer le gain à partir d'un seuil </center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_seuil(seuil):\n",
    "    def seuil_pred(row, seuil):\n",
    "        if row['1 probability'] > seuil and row['SeriousDlqin2yrs'] == 0:\n",
    "            row['error'] = 'FP'\n",
    "        if row['1 probability'] > seuil and row['SeriousDlqin2yrs'] == 1:\n",
    "            row['error'] = 'TP'\n",
    "        if row['1 probability'] < seuil and row['SeriousDlqin2yrs'] == 0:\n",
    "            row['error'] = 'TN'\n",
    "        if row['1 probability'] < seuil and row['SeriousDlqin2yrs'] == 1:\n",
    "            row['error'] = 'FN'\n",
    "        return row\n",
    "\n",
    "    for data in [df]:\n",
    "        data['error'] = df[['error', '1 probability', 'SeriousDlqin2yrs']].apply(seuil_pred, axis=1, seuil = seuil)\n",
    "\n",
    "    count = data['error'].value_counts()\n",
    "    gain = 1\n",
    "    if \"TP\" not in  data['error']:\n",
    "        if \"FP\" not in  data['error']:\n",
    "            gain = count[0]*500 - count[1]*2500\n",
    "        else:\n",
    "            gain = count[0]*500 - count[1]*2500 - count[3]*500\n",
    "    else:\n",
    "        gain = count[0]*500 - count[1]*2500 - count[2]*500\n",
    "\n",
    "    return gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [gain_seuil(n/100) for n in range(1,100)]\n",
    "seuil = [(n/100) for n in range(1,100)]\n",
    "plt.plot(table)\n",
    "plt.ylabel(\"Seuil\")\n",
    "plt.xlabel(\"Gain\")\n",
    "plt.title('Gain maximisé')\n",
    "max_val = max(table)\n",
    "max_threshold = table.index(max_val)\n",
    "print(f'Le gain maximum est {max_val} et il est obtenu avec un seuil de {max_threshold}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center> Récupérer les 100 plus grosses erreurs </center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['absolute_error'] = (df['1 probability']-df['SeriousDlqin2yrs']).abs()\n",
    "desc_order = df.sort_values(by='absolute_error', ascending = False).head(100)\n",
    "desc_order.to_csv('../handson-ml2/100error.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center> Calculer l'AUC </center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "score = roc_auc_score(df['SeriousDlqin2yrs'].values,df['1 probability'].values)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positif = df.loc[df['SeriousDlqin2yrs'] == 1] # Tout les Positif \n",
    "negatif = df.loc[df['SeriousDlqin2yrs'] == 0] # Tout les negatifs \n",
    "\n",
    "x = 0\n",
    "y = 0\n",
    "# pour chaque 1 proba ( P ) dans toutes les 1 proba (P)\n",
    "for threshold_pos in positif['1 probability']:\n",
    "    # pour chaque 1 Proba ( N ) dans toutes les 1 proba ( N )\n",
    "    for threshold_neg in negatif['1 probability']:\n",
    "        if threshold_pos > threshold_neg:\n",
    "            x += 1 \n",
    "        y += 1 \n",
    "print(f\"L'AUC est égale à {round((x/y)*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nombre_supérieur = 0\n",
    "nombre_iteration = 0\n",
    "serie = df.transpose() # here we convert the DataFrame into a Serie\n",
    "for ligne in serie:\n",
    "    if serie[ligne]['SeriousDlqin2yrs'] == 1: \n",
    "        proba_positif = serie[ligne]['1 probability'] # On stocke la valeur de 1 probability à la variable proba_positif\n",
    "        for ligne_neg in serie: \n",
    "            if serie[ligne_neg]['SeriousDlqin2yrs'] == 0:\n",
    "                if proba_positif > serie[ligne_neg]['1 probability']: # Si la valeur de proba_positif est inférieure à la valeur de 1 probability\n",
    "                    nombre_supérieur += 1 # On incrémente la valeur de 1\n",
    "                nombre_iteration += 1 # On incrémente le nombre de boucle total (dénominateur pour le calcul de l'AUC)\n",
    "\n",
    "print(nombre_supérieur)\n",
    "print(nombre_iteration)\n",
    "print(f\"{nombre_supérieur/nombre_iteration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sixième étape: Préparer les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv('../handson-ml2/kaggle-give-me-credit-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Unnamed: 0\": \"Id\"})\n",
    "df['IncomePerPerson'] = df['MonthlyIncome']/ (df['NumberOfDependents']+1)\n",
    "df['NumberOfDaysLate'] = df['NumberOfTimes90DaysLate']+ df['NumberOfTime60-89DaysPastDueNotWorse']+ df['NumberOfTime30-59DaysPastDueNotWorse']\n",
    "df['NumberCreditLines'] = df['NumberOfOpenCreditLinesAndLoans']- df['NumberRealEstateLoansOrLines']\n",
    "df['MonthlyDebt'] = df['MonthlyIncome'] * df['DebtRatio']\n",
    "df['MonthlyBalance'] = df['MonthlyIncome'] - df['MonthlyDebt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center> Créer un dataset de test </center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_source = api.create_source('../handson-ml2/test.csv')\n",
    "api.ok(test_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = api.create_dataset(test_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Septième étape: Modèle avec le trainfull/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble1 = api.create_ensemble(origin_dataset, {\"objective_field\":\"SeriousDlqin2yrs\"})\n",
    "api.ok(ensemble1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction1 = api.create_batch_prediction(ensemble1, test_dataset, {\"output_fields\": [\"Id\"], \"probabilities\": True})\n",
    "api.ok(batch_prediction1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.download_batch_prediction(batch_prediction1, filename='../handson-ml2/my_predictionsfinales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huitième étape: Soumission à Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = read_csv('../handson-ml2/my_predictionsfinales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center> Mettre au bon format pour kaggle </center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = submit.rename(columns={\"1 probability\": \"Probability\"})\n",
    "submit = submit.drop(columns={\"0 probability\", \"SeriousDlqin2yrs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"submitkaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file = \"submitkaggle.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center> Soumission à kaggle </center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.api.competition_submit(submission_file, \"BigML model\", \"GiveMeSomeCredit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
