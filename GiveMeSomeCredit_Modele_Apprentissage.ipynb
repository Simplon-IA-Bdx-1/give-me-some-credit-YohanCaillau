{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Modèle d'apprentissage Train/Val </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigml.api import BigML\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = BigML(project= 'project/5d94a407eba31d45c8000088')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = api.create_source('../handson-ml2/trainfull.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_dataset = api.create_dataset(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = api.create_dataset (origin_dataset, {\"name\": \"Train80\", \"sample_rate\":0.8, \"seed\": \"myseed\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = api.create_dataset (origin_dataset, {\"name\": \"Val\", \"sample_rate\":0.8, \"seed\": \"myseed\", \"out_of_bag\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Learning Curves Split en 10%\n",
    "x_ensemble = []\n",
    "y_ensemble = []\n",
    "x_deepnet = []\n",
    "y_deepnet = []\n",
    "for i in range(1,11): \n",
    "    # On crée le nouveau dataset de train à partir du dataset de train80 en itérant les 10 %\n",
    "    dataset_train_split = api.create_dataset(train_dataset, {\"name\": \"Dataset Train Split\" + str(i/10), \"sample_rate\": i/10, \"seed\": \"my seed\"})    \n",
    "    # On crée le modèle (ensemble) à partir du dataset spliter\n",
    "    ensemble = api.create_ensemble(dataset_train_split, {\"objective_field\" : \"SeriousDlqin2yrs\", \"name\": \"Ensemble \" + str(i/10)})\n",
    "    api.ok(ensemble)\n",
    "    # On évalue le nouveau modèle (ensemble) qui va nous donner l'AUC\n",
    "    evaluation = api.create_evaluation(ensemble, val_dataset )\n",
    "    api.ok(evaluation)\n",
    "    # On fait la même chose pour deepnet\n",
    "    deepnet = api.create_deepnet(dataset_train_split, {\"objective_field\" : \"SeriousDlqin2yrs\", \"name\": \"Deepnet \" + str(i/10)})\n",
    "    api.ok(deepnet)\n",
    "    evaluation_deepnet = api.create_evaluation(deepnet, val_dataset )\n",
    "    api.ok(evaluation_deepnet)\n",
    "    \n",
    "    x_ensemble.append(i*10)\n",
    "    y_ensemble.append(evaluation['object']['result']['model']['average_area_under_roc_curve'])\n",
    "    x_deepnet.append(i*10)\n",
    "    y_deepnet.append(evaluation_deepnet['object']['result']['model']['average_area_under_roc_curve'])\n",
    "    i += 1\n",
    "\n",
    "print(x_ensemble)\n",
    "print(y_ensemble)\n",
    "print(x_deepnet)\n",
    "print(y_deepnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = plt.plot(x_ensemble, y_ensemble, color='darkblue', label ='ensemble')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Taille du dataset train en %')\n",
    "g2 = plt.plot(x_deepnet, y_deepnet, color='red', label ='deepnet')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center>Lancement d'un Modèle ou d'un Deepnet ou autre...</center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = api.create_ensemble(train_dataset, {\"objective_field\":\"SeriousDlqin2yrs\"})\n",
    "api.ok(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet = api.create_deepnet(train_dataset, {\"objective_field\":\"SeriousDlqin2yrs\"})\n",
    "api.ok(deepnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optiml = api.create_optiml(train_dataset, {\"objective_field\":\"SeriousDlqin2yrs\", \"metric\": \"accuracy\"})\n",
    "api.ok(optiml)\n",
    "api.status(optiml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center> Evaluation du modèle </center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = api.create_evaluation(ensemble, val_dataset)\n",
    "api.status(evaluation)\n",
    "api.ok(evaluation)\n",
    "evaluation = api.get_evaluation(evaluation)\n",
    "api.pprint(evaluation['object']['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation2 = api.create_evaluation(deepnet, val_dataset)\n",
    "api.status(evaluation2)\n",
    "api.ok(evaluation2)\n",
    "evaluation2 = api.get_evaluation(evaluation2)\n",
    "api.pprint(evaluation2['object']['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center>Lancer la prediction à partir de notre modèle en demandant les probabilités</center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction = api.create_batch_prediction(ensemble, val_dataset, {\"all_fields\": True, \"header\": True, \"probabilities\": True})\n",
    "api.ok(batch_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction2 = api.create_batch_prediction(deepnet, val_dataset, {\"all_fields\": True, \"header\": True, \"probabilities\": True})\n",
    "api.ok(batch_prediction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<center>Récupérer la batch prediction au format csv</center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.download_batch_prediction(batch_prediction, filename='../handson-ml2/my_predictionsValEnsemble.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.download_batch_prediction(batch_prediction2, filename='../handson-ml2/my_predictionsValDeepnet.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
